# Cloud Trace Analyzer Agent

[![Status](https://img.shields.io/badge/Status-Active-success)]()
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)]()
[![Framework](https://img.shields.io/badge/Framework-Google%20ADK-red)]()


A Google ADK-based agent that performs deep diff analysis on distributed traces from Cloud Trace. It compares baseline (normal) traces to abnormal traces to identify performance regressions, errors, and behavioral changes using a "squad" of specialized analysis sub-agents.

## Features

- **Parallel Analysis Squads**: Uses **6 specialized agents** divided into Triage (Latency, Error, Structure, Statistics) and Deep Dive (Causality, Service Impact) squads to analyze traces concurrently.
- **Hybrid BigQuery Integration**: Leverages BigQuery via MCP (Model Context Protocol) for statistical analysis over large datasets and long time ranges.
- **Automatic Trace Discovery**: Intelligently identifies representative baseline (P50) and anomaly (P95 or error) traces for comparison.
- **Advanced Trace Filtering**: Supports complex filters including service names, HTTP status codes, min/max latency, and custom attribute matching.
- **Root Cause Synthesis**: Automatically identifies the critical path and performs causal analysis to explain *why* a trace is slow or failing.
- **Cloud Console Integration**: Directly analyze traces by pasting their Google Cloud Console URL.

## Architecture

The agent is built using the Google Agent Development Kit (ADK) and follows a hierarchical orchestration pattern:

```mermaid
sequenceDiagram
    %% 'neutral' theme adapts best to dark/light modes. 
    %% wrap: true helps text fitting.
    %%{init: {
        'theme': 'neutral', 
        'themeVariables': { 
            'fontFamily': 'arial',
            'fontSize': '14px'
        }
    }}%%
    
    autonumber
    
    box "ğŸ“¢ Request Origin"
        actor User as ğŸ‘¤ User
        participant Agent as ğŸ•µï¸ Trace Detective
    end
    
    box "ğŸ› ï¸ The Toolbox"
        participant Tools as Discovery<br/>Tools
    end
    
    box "ğŸš¨ The Squads"
        participant S1 as Triage<br/>Squad
        participant S2 as Deep Dive<br/>Squad
    end

    User->>Agent: "Analyze these traces..."
    
    %% Using <br/> and shorter dividers reduces width significantly
    Note over User, S2: â”€â”€ PHASE 1: EVIDENCE GATHERING â”€â”€
    
    Agent->>Tools: Fetch Trace Data<br/>(Baseline vs Target)
    activate Tools
    Tools-->>Agent: Trace Data
    deactivate Tools

    Note over User, S2: â”€â”€ PHASE 2: IDENTIFICATION â”€â”€
    
    Agent->>S1: run_triage_analysis()
    activate S1
    S1->>S1: Parallel Analysis<br/>(Latency, Error, Structure)
    S1-->>Agent: Triage Report<br/>(Suspects Found)
    deactivate S1
    
    Agent->>User: "I found latency spikes in Service X..."

    Note over User, S2: â”€â”€ PHASE 3: ROOT CAUSE â”€â”€
    
    User->>Agent: "Dig deeper into Service X"
    
    Agent->>S2: run_deep_dive_analysis()
    activate S2
    S2->>S2: Causal & Impact Analysis
    S2-->>Agent: Deep Dive Report<br/>(Root Cause)
    deactivate S2

    Note over User, S2: â”€â”€ PHASE 4: VERDICT â”€â”€
    
    Agent->>User: ğŸ“‚ FINAL CASE FILE<br/>(Root Cause + Fixes)
```

### Core Components
- **Trace Detective (Root)**: The orchestrator with a "Detective" persona that synthesizes findings into a "Case File". It uses an interactive workflow, reporting Triage findings first before proceeding to Deep Dive.
- **Triage Squad (Stage 1)**: Rapidly identifies *what* is wrong (Latency, Errors, Structure, Stats).
- **Deep Dive Squad (Stage 2)**: Investigates *why* it happened (Causality) and *who* else is affected (Service Impact).
- **Dynamic MCP Integration**: Uses `ApiRegistry` to lazily load BigQuery tools, ensuring cross-platform stability.

## Setup

### 1. Install Dependencies

The project uses `uv` for high-performance dependency management:

```bash
cd trace_analyzer
uv sync
```

### 2. Configure Environment

Copy the example environment file and configure your Google Cloud project:

```bash
cp .env.example .env
```

Key variables in `.env`:
```bash
# Required for Cloud Trace and BigQuery access
GOOGLE_CLOUD_PROJECT=your-gcp-project
GOOGLE_CLOUD_LOCATION=us-central1

# Agent Engine Configuration
GOOGLE_GENAI_USE_VERTEXAI=1
```

### 3. Ensure IAM Permissions

The authenticated user or service account requires:
- `roles/cloudtrace.user`
- `roles/bigquery.dataViewer`
- `roles/bigquery.jobUser`

## Deployment

### Deployment (Standard ADK CLI)
 
 If you prefer using the standard `adk` CLI, you can pass environment variables via an env file:
 
 ```bash
 # 1. Ensure env vars are in trace_analyzer/telemetry.env
 # 2. Deploy using the --env_file flag
 uv run adk deploy agent_engine \
   --project=your-project \
   --region=us-central1 \
   --staging_bucket=your-bucket \
   --display_name="Trace Analyzer" \
   --env_file trace_analyzer/telemetry.env \
   trace_analyzer
 ```
 
 ### Deployment (Custom Script)
 
 We also provide a custom deployment script that supports direct flags:
 
 ```bash
 # Basic deployment
 uv run python deploy/deploy.py --create
 ```

The script will create a Reasoning Engine (Agent Engine) resource and output its resource name.

## Usage

### Running the Agent

```bash
# Launch the interactive terminal UI
uv run adk run .

# Launch the web-based interface
uv run adk web
```

### Example Prompts

**Trend Analysis & Discovery:**
> "Find example traces in my project from the last 4 hours and show me what's different between a typical request and a slow one."

**Specific Investigation:**
> "Analyze this trace from the production console: https://console.cloud.google.com/traces/details/[TRACE_ID]?project=[PROJECT_ID]"

**Service-Specific Filtering:**
> "Find traces for the 'payment-processor' service with latency > 500ms and compare them to the baseline."

**BigQuery Powered Queries:**
> "Use BigQuery to find the most frequent error patterns in my traces over the last 24 hours."

## Project Structure

```
trace_analyzer/
â”œâ”€â”€ trace_analyzer/
â”‚   â”œâ”€â”€ agent.py          # Root orchestrator ("Trace Detective")
â”‚   â”œâ”€â”€ sub_agents/       # Specialized analysis agents
â”‚   â”‚   â”œâ”€â”€ latency/      # Latency Analyzer
â”‚   â”‚   â”œâ”€â”€ error/        # Error Analyzer
â”‚   â”‚   â”œâ”€â”€ structure/    # Structure Analyzer
â”‚   â”‚   â”œâ”€â”€ statistics/   # Statistics Analyzer
â”‚   â”‚   â”œâ”€â”€ causality/    # Causality Analyzer
â”‚   â”‚   â””â”€â”€ service_impact/ # Service Impact Analyzer
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ trace_client.py   # Cloud Trace API wrapper
â”‚   â”‚   â”œâ”€â”€ trace_filter.py   # Advanced TraceQueryBuilder
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ prompt.py         # Advanced multi-turn prompting logic
â”œâ”€â”€ tests/                # Comprehensive test suite
â”œâ”€â”€ deployment/           # Deployment scripts
â”œâ”€â”€ AGENTS.md             # Developer & Contributor guide
â”œâ”€â”€ pyproject.toml        # uv-based build configuration
â””â”€â”€ README.md
```

## Reliability & Performance

## Reliability & Performance

- **Lazy MCP Loading**: Implements `LazyMcpRegistryToolset` to prevent session conflicts in ASGI/uvicorn environments, ensuring stable deployment.
- **Observability**: Fully instrumented with OpenTelemetry for tracking tool execution and agent performance.
- **Truncation & Noise Reduction**: Advanced logging patterns ensure that large trace datasets don't overwhelm LLM context windows.

## Troubleshooting

- **`ValueError: stale session`**: This usually happens if the local database state gets out of sync with the running agent. Try clearing the `.adk` directory or restarting the server.
- **Permission Errors**: Ensure you have run `gcloud auth application-default login` and that your user has `roles/cloudtrace.user` and `roles/bigquery.dataViewer`.
- **ASGI Errors**: If you see "ASGI callable returned without completing response", ensure you are using the latest version of the ADK and that `LazyMcpRegistryToolset` is being used for MCP tools.

## Contributing

See [AGENTS.md](./AGENTS.md) for detailed developer workflows, testing instructions, and PR guidelines.

## License

Apache-2.0
