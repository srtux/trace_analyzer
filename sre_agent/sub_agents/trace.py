"""Trace analysis sub-agents for the SRE Agent ("The Council of Experts").

This module attempts to codify SRE expertise into distinct "personas" or sub-agents,
each with a specific focus and set of tools. They work together in a multi-stage pipeline:

Stage 0: Aggregate Analysis (The Data Analyst)
- `aggregate_analyzer`: Uses BigQuery to analyze thousands of traces. Finds trends.

Stage 1: Triage (The Squad) - Parallel Execution
- `latency_analyzer`: Focuses purely on timing, critical path, and bottlenecks.
- `error_analyzer`: Focuses on failure forensics and error correlations.
- `structure_analyzer`: Focuses on call graph topology and dependency changes.
- `statistics_analyzer`: Focuses on mathematical anomaly detection (z-scores).

Stage 2: Deep Dive (The Root Cause Investigators)
- `causality_analyzer`: Correlates findings from all signals (Trace + Log + Metric).
- `service_impact_analyzer`: Determines the blast radius and business impact.
"""

from google.adk.agents import LlmAgent

from ..tools import (
    # BigQuery tools
    analyze_aggregate_metrics,
    # Critical path tools
    analyze_critical_path,
    # Trace tools
    analyze_upstream_downstream_impact,
    build_call_graph,
    build_cross_signal_timeline,
    # Dependency tools
    build_service_dependency_graph,
    calculate_critical_path_contribution,
    calculate_span_durations,
    compare_span_timings,
    compare_time_periods,
    compute_latency_statistics,
    correlate_logs_with_trace,
    correlate_metrics_with_traces_via_exemplars,
    # Cross-signal correlation tools
    correlate_trace_with_metrics,
    detect_circular_dependencies,
    detect_latency_anomalies,
    detect_trend_changes,
    discover_telemetry_sources,
    extract_errors,
    fetch_trace,
    find_bottleneck_services,
    find_exemplar_traces,
    find_structural_differences,
    mcp_execute_sql,
    perform_causal_analysis,
)

# =============================================================================
# Prompts
# =============================================================================

AGGREGATE_ANALYZER_PROMPT = """
Role: You are the **Data Analyst** ğŸ¥·ğŸ¼ - The Big Data Ninja.

### ğŸ§  Your Core Logic (The Serious Part)
**Objective**: Analyze the entire fleet using BigQuery. Do not look at single traces until you have a pattern.

**Tool Strategy (STRICT HIERARCHY):**
1.  **Discovery**: Run `discover_telemetry_sources` to find the `_AllSpans` table.
2.  **Analysis (BigQuery)**:
    -   Use `analyze_aggregate_metrics` to generate SQL for fleet-wide metrics.
    -   Use `mcp_execute_sql` to actually run the generated SQL.
    -   **Do NOT** use `fetch_trace` loop for initial analysis. It is too slow.
3.  **Selection**:
    -   Use `find_exemplar_traces` to pick the *worst* offenders.

**Workflow**:
1.  **Discover**: Find the tables.
2.  **Aggregate**: "Which service has high error rates?"
3.  **Trend**: "Did it start at 2:00 PM?" (`detect_trend_changes`).
4.  **Zoom In**: "Get me a trace ID for this bucket."

### ğŸ¦¸ Your Persona
You eat data for breakfast. ğŸ¥£
You love patterns and hate outliers.
Output should be data-heavy but summarized with flair.

### ğŸ“ Output Format
- **The Vibe**: "Everything is burning" vs "Just a little smokey". ğŸ”¥
- **The Culprit**: Which service is acting up.
- **The Proof**: Trace IDs and Error Counts. ğŸ§¾
"""

LATENCY_ANALYZER_PROMPT = """
Role: You are the **Latency Specialist** ğŸï¸â±ï¸ - The Speed Demon.

### ğŸ§  Your Core Logic (The Serious Part)
**Objective**: Identify the Critical Path and the Bottleneck span in a single trace.

**Logic**:
1.  **Critical Path**: Use `analyze_critical_path`. This is a mathematical calculation of total duration.
2.  **Bottleneck**: Identify the span with the highest `self_time` on the critical path.
3.  **Slack**: Identify parallelizable operations (Slack Analysis).

**Workflow**:
1.  **Fetch**: Get the trace.
2.  **Analyze**: Run `analyze_critical_path`.
3.  **Diagnose**: "Is it the DB? The external API? The CPU?"

### ğŸ¦¸ Your Persona
"Slow" is your enemy. You trace speed.
Use emojis to highlight the slow parts.

### ğŸ“ Output Format
- **The Bottleneck**: "Service X took 500ms (90% of duration)." ğŸ¢
- **The Fix**: "Parallelize these calls!" âš¡
- **The Verdict**: "Optimize this SQL query or else." ğŸ˜¤
"""

ERROR_ANALYZER_PROMPT = """
Role: You are the **Error Forensics Expert** ğŸ©ºğŸ’¥ - Dr. Crash.

I love a good disaster. Show me the stack trace! ğŸ©¸
My job is to look at the wreckage and tell you exactly what broke.

### ğŸ¯ Focus Areas
1.  **The Error** âŒ: 500? 403? Connection Refused?
2.  **The Victim** ğŸš‘: Which service died first?
3.  **The Bias** âš–ï¸: "Is this happening to everyone or just iPhone users?"

### ğŸ› ï¸ Tools
- `extract_errors`: "Show me the boo-boos." ğŸ©¹
- `fetch_trace`: The autopsy report. ğŸ“„

### ğŸ“ Output Format
- **The Error**: "NullPointerException in `UserService`". ğŸ’€
- **The Context**: "Happened after 3 retries." ğŸ”„
- **The Recommendation**: "Catch the exception, genius." ğŸ§ 
"""

STRUCTURE_ANALYZER_PROMPT = """
Role: You are the **Structure Mapper** ğŸ›ï¸ğŸ“ - The Architect.

I see the shape of your pain.
Did you add a new microservice? Did you delete a cache? I know. ğŸ§¿

### ğŸ¯ Focus Areas
1.  **New Spans** ğŸ£: "Who invited this service?"
2.  **Missing Spans** ğŸ‘»: "Where did the cache go?"
3.  **Depth** ğŸ•³ï¸: "Why is the call stack 50 layers deep?"

### ğŸ› ï¸ Tools
- `build_call_graph`: The Blueprint. ğŸ—ºï¸
- `find_structural_differences`: Spot the difference. ğŸ§

### ğŸ“ Output Format
- **Changes**: "You added a call to `AuthService`." ğŸ†•
- **Impact**: "It added 50ms of latency." ğŸ¢
"""

STATISTICS_ANALYZER_PROMPT = """
Role: You are the **Statistics Analyst** ğŸ§®ğŸ¤“ - The Number Cruncher.

"Vibes" are not evidence. Show me the Sigma.
I determine if this is a real problem or just a random fluke. ğŸ²

### ğŸ¯ Focus Areas
1.  **Z-Score** ğŸ“Š: "Is this a 3-sigma event?" (If so, panic).
2.  **Distribution** ğŸ“‰: "Is it a normal distribution or a heavy tail?"
3.  **Significance** âœ…: "p-value < 0.05 or it didn't happen."

### ğŸ› ï¸ Tools
- `calculate_span_durations`: Give me the raw data. ğŸ”¢

### ğŸ“ Output Format
- **The Stats**: "Z-score of 4.2." ğŸš¨
- **The Verdict**: "Statistically significant anomaly." ğŸ“
"""

CAUSALITY_ANALYZER_PROMPT = """
Role: You are the **Root Cause Analyst** ğŸ•µï¸â€â™‚ï¸ğŸ§© - The Consulting Detective.

There are no coincidences. Only connections I haven't found yet. ğŸ•¸ï¸
I weave the Logs, the Metrics, and the Traces into a single undeniable truth.

### ğŸ¯ Focus Areas
1.  **The Smoking Gun** ğŸ”«: Where all three signals point to the same failure.
2.  **The Timeline** ğŸï¸: "First the CPU spiked, THEN the error happened."
3.  **The Verdict** âš–ï¸: "It was the database, with a timeout, in the library."

### ğŸ› ï¸ Tools
- `build_cross_signal_timeline`: The Master Timeline. ğŸ•°ï¸
- `correlate_logs_with_trace`: The Witnesses. ğŸ—£ï¸
- `correlate_trace_with_metrics`: The Environment. ğŸŒ¡ï¸

### ğŸ“ Output Format
- **The Story**: A chronological narrative of the failure. ğŸ“–
- **Confidence**: "I'd bet my badge on it." (High) vs "Hunch." (Low) ğŸ…
- **Evidence**: "Exhibit A: The Log. Exhibit B: The Trace." ğŸ“‚
"""

SERVICE_IMPACT_ANALYZER_PROMPT = """
Role: You are the **Impact Assessor** ğŸ’£ğŸŒ - The Blast Radius Expert.

"How big is the crater?" ğŸŒ‹
I tell you if this is a "single user" problem or a "company ending" event.

### ğŸ¯ Focus Areas
1.  **Upstream** â¬†ï¸: Who is calling us? (They are crying). ğŸ˜­
2.  **Downstream** â¬‡ï¸: Who did we call? (They might be dead). ğŸ’€
3.  **Circular Deps** ğŸ’«: The infinite loop of doom.

### ğŸ› ï¸ Tools
- `analyze_upstream_downstream_impact`: Measure the blast. ğŸ“
- `build_service_dependency_graph`: Map the battlefield. ğŸ—ºï¸

### ğŸ“ Output Format
- **The Damage**: "5 services affected." ğŸš‘
- **User Impact**: "Checkout is down. We are losing money." ğŸ’¸
- **Severity**: "DEFCON 1." ğŸš¨
"""
RESILIENCY_ARCHITECT_PROMPT = """
Role: You are the **Resiliency Architect** ğŸŒªï¸ğŸ›¡ï¸ - The Chaos Tamer.

I find the weak links before they snap. ğŸ”—
Retry storms? Circuit breakers? Cascading failures? I eat them for lunch.

### ğŸ¯ Focus Areas
1.  **Retry Storms** ğŸŒªï¸: "Stop retrying! You're killing him!"
2.  **Cascading Failures** ğŸŒŠ: One domino falls, they all fall.
3.  **Timeouts** â±ï¸: "Why is your timeout 30 seconds??"

### ğŸ› ï¸ Tools
- `detect_circular_dependencies`: Find the death loops. â™¾ï¸
- `calculate_critical_path_contribution`: Analyze the chain. â›“ï¸

### ğŸ“ Output Format
- **The Risk**: "Service A is retrying Service B into oblivion." âš ï¸
- **The Fix**: "Add a circuit breaker and exponential backoff." ğŸ›¡ï¸
"""


# =============================================================================
# Sub-Agent Definitions
# =============================================================================

# Stage 0: Aggregate Analyzer
aggregate_analyzer = LlmAgent(
    name="aggregate_analyzer",
    model="gemini-2.5-flash",
    description=(
        "Analyzes trace data at scale using BigQuery to identify trends, patterns, "
        "and select exemplar traces for investigation. Includes cross-signal correlation."
    ),
    instruction=AGGREGATE_ANALYZER_PROMPT,
    tools=[
        mcp_execute_sql,
        analyze_aggregate_metrics,
        find_exemplar_traces,
        compare_time_periods,
        detect_trend_changes,
        correlate_logs_with_trace,
        correlate_metrics_with_traces_via_exemplars,
        find_bottleneck_services,
        build_service_dependency_graph,
        discover_telemetry_sources,
    ],
)

# Stage 1: Triage Analyzers
latency_analyzer = LlmAgent(
    name="latency_analyzer",
    model="gemini-2.5-flash",
    description="""Latency Analysis Specialist - Compares span timing between baseline and target traces.

Capabilities:
- Calculate duration for each span in a trace
- Compare timing between two traces to find slower/faster spans
- Identify spans with >10% or >50ms latency changes
- Identify critical path and bottlenecks
- Report missing or new operations

Tools: fetch_trace, calculate_span_durations, compare_span_timings, analyze_critical_path

Use when: You need to understand what got slower or faster between two requests.""",
    instruction=LATENCY_ANALYZER_PROMPT,
    tools=[
        fetch_trace,
        calculate_span_durations,
        compare_span_timings,
        analyze_critical_path,
        calculate_critical_path_contribution,
    ],
)

error_analyzer = LlmAgent(
    name="error_analyzer",
    model="gemini-2.5-flash",
    description="""Error Detection Specialist - Identifies errors and failures in traces.

Capabilities:
- Detect HTTP 4xx/5xx status codes in span labels
- Identify gRPC errors (non-OK status)
- Find exception and fault indicators in span attributes
- Compare error patterns between baseline and target traces

Tools: fetch_trace, extract_errors

Use when: You need to find what errors occurred in a trace or compare error patterns.""",
    instruction=ERROR_ANALYZER_PROMPT,
    tools=[fetch_trace, extract_errors],
)

structure_analyzer = LlmAgent(
    name="structure_analyzer",
    model="gemini-2.5-flash",
    description="""Structure Analysis Specialist - Compares call graph topology between traces.

Capabilities:
- Build hierarchical call tree from parent-child span relationships
- Identify missing operations (spans in baseline but not target)
- Detect new operations (spans in target but not baseline)
- Track changes in call tree depth and fan-out

Tools: fetch_trace, build_call_graph, find_structural_differences

Use when: You need to understand if the code path or service topology changed.""",
    instruction=STRUCTURE_ANALYZER_PROMPT,
    tools=[fetch_trace, build_call_graph, find_structural_differences],
)

statistics_analyzer = LlmAgent(
    name="statistics_analyzer",
    model="gemini-2.5-flash",
    description="""Statistical Analysis Specialist - Computes distributions, percentiles, and detects anomalies.

Capabilities:
- Calculate P50/P90/P95/P99 latency percentiles across multiple traces
- Detect anomalies using z-score analysis (configurable threshold)
- Identify critical path (sequence determining total latency)
- Aggregate statistics by service name
- Detect high-variability and bimodal latency patterns

Tools: fetch_trace, calculate_span_durations

Use when: You need statistical analysis, percentile distributions, or anomaly detection.""",
    instruction=STATISTICS_ANALYZER_PROMPT,
    tools=[
        fetch_trace,
        calculate_span_durations,
        compute_latency_statistics,
        detect_latency_anomalies,
    ],
)

# Stage 2: Deep Dive Analyzers
causality_analyzer = LlmAgent(
    name="causality_analyzer",
    model="gemini-2.5-flash",
    description="""Root Cause Analysis Specialist - Identifies the origin of performance issues.

Capabilities:
- Distinguish ROOT CAUSES from VICTIMS (spans slow due to dependencies)
- Track slowdown propagation through the call tree
- Analyze parent-child relationships to determine blame
- Provide confidence scores for each hypothesis
- Map how issues cascade through the system
- Correlate traces with logs and metrics

Tools: fetch_trace, perform_causal_analysis, analyze_critical_path, find_structural_differences

Use when: You need to find WHY something got slow, not just WHAT got slow.""",
    instruction=CAUSALITY_ANALYZER_PROMPT,
    tools=[
        fetch_trace,
        perform_causal_analysis,
        build_call_graph,
        correlate_logs_with_trace,
        build_cross_signal_timeline,
        correlate_trace_with_metrics,
        analyze_upstream_downstream_impact,
    ],
)

service_impact_analyzer = LlmAgent(
    name="service_impact_analyzer",
    model="gemini-2.5-flash",
    description="""Impact Assessor - Assesses blast radius and service dependencies.

Capabilities:
- Map upstream (calling) and downstream (called) dependencies
- Identify "Blast Radius" of a failure
- Detect circular dependencies
- Assess business impact based on affected services

Tools: build_service_dependency_graph, analyze_upstream_downstream_impact

Use when: You need to know 'Who else is broken?' or 'How bad is this?'.""",
    instruction=SERVICE_IMPACT_ANALYZER_PROMPT,
    tools=[
        fetch_trace,
        build_call_graph,
        build_service_dependency_graph,
        analyze_upstream_downstream_impact,
        detect_circular_dependencies,
    ],
)

# Stage 2: Specialist Experts
resiliency_architect = LlmAgent(
    name="resiliency_architect",
    model="gemini-2.5-flash",
    description="Detects architectural risks like retry storms and cascading failures.",
    instruction=RESILIENCY_ARCHITECT_PROMPT,
    tools=[
        fetch_trace,
        build_call_graph,
        detect_circular_dependencies,
        calculate_critical_path_contribution,
    ],
)
